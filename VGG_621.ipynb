{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG_621.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/stpraha/vgg_fer2013/blob/master/VGG_621.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "vOI9qb_RY5u1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "063b3b26-e9e6-4ff9-90fc-4c7cd6954b65"
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sat Jun 16 10:00:07 2018\n",
        "\n",
        "@author: Administrator\n",
        "\"\"\"\n",
        "from datetime import datetime\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "\n",
        "f_train = open(\"drive//fer2013//traincpy.csv\", encoding = 'UTF-8')\n",
        "df_train = pd.read_csv(f_train)\n",
        "f_test_pub = open(\"drive//fer2013//valcpy.csv\", encoding = 'UTF-8')\n",
        "df_test_pub = pd.read_csv(f_test_pub)\n",
        "f_test_pri = open(\"drive//fer2013//testcpy.csv\", encoding = 'UTF-8')\n",
        "df_test_pri = pd.read_csv(f_test_pri)\n",
        "\n",
        "train_featuresets = df_train.iloc[1: , 1: ]\n",
        "train_emotionsets = df_train.iloc[1: , 0:1]\n",
        "test_pub_featuresets = df_test_pub.iloc[0: , 1: ]\n",
        "test_pub_emotionsets = df_test_pub.iloc[0: , 0:1]\n",
        "test_pri_featuresets = df_test_pri.iloc[0: , 1: ]\n",
        "test_pri_emotionsets = df_test_pri.iloc[0: , 0:1]\n",
        "\n",
        "#train_feature = tf.constant(train_featuresets)\n",
        "#train_emotion = tf.constant(train_emotionsets)\n",
        "\n",
        "#train_feature = tf.reshape(train_feature, [-1, 48, 48, 1])\n",
        "#train_emotion = tf.reshape(train_emotion, [-1, 1])\n",
        "\n",
        "#双线性插值，讲48*48的图片变成224*224\n",
        "\n",
        "def resize(src, new_size):\n",
        "    dst_w = 224\n",
        "    dst_h = 224 # 目标图像宽高\n",
        "    src_h = 48\n",
        "    src_w = 48 # 源图像宽高\n",
        "    if src_h == dst_h and src_w == dst_w:\n",
        "        return src.copy()\n",
        "    scale_x = float(src_w) / dst_w # x缩放比例\n",
        "    scale_y = float(src_h) / dst_h # y缩放比例\n",
        "\n",
        "    # 遍历目标图像，插值\n",
        "    dst = np.zeros((dst_h, dst_w, 1), dtype=np.uint8)\n",
        "    for n in range(1): # 对channel循环\n",
        "        for dst_y in range(dst_h): # 对height循环\n",
        "            for dst_x in range(dst_w): # 对width循环\n",
        "                # 目标在源上的坐标\n",
        "                src_x = (dst_x + 0.5) * scale_x - 0.5\n",
        "                src_y = (dst_y + 0.5) * scale_y - 0.5\n",
        "                # 计算在源图上四个近邻点的位置\n",
        "                src_x_0 = int(np.floor(src_x))\n",
        "                src_y_0 = int(np.floor(src_y))\n",
        "                src_x_1 = min(src_x_0 + 1, src_w - 1)\n",
        "                src_y_1 = min(src_y_0 + 1, src_h - 1)\n",
        "\n",
        "                #双线性插值\n",
        "                value0 = (src_x_1 - src_x) * src[src_y_0, src_x_0, n] + (src_x - src_x_0) * src[src_y_0, src_x_1, n]\n",
        "                value1 = (src_x_1 - src_x) * src[src_y_1, src_x_0, n] + (src_x - src_x_0) * src[src_y_1, src_x_1, n]\n",
        "                dst[dst_y, dst_x, n] = int((src_y_1 - src_y) * value0 + (src_y - src_y_0) * value1)\n",
        "    return dst\n",
        "\n",
        "\n",
        "print('hrhere')\n",
        "train_feature_resize = []\n",
        "train_feature = np.reshape(np.array(train_featuresets, dtype = 'float32'), (-1, 48, 48, 1))\n",
        "train_emotion = np.reshape(np.array(train_emotionsets, dtype = 'float32'), (-1))\n",
        "for i in range(train_feature.shape[0]):\n",
        "    if i%1000 == 0:\n",
        "        print('now resize 48 --> 224 train set')\n",
        "    train_feature_resize.append(resize(train_feature[i], 224))\n",
        "train_feature_resize = np.reshape(np.array(train_feature_resize, dtype = 'float32'), (-1, 224, 224,1))\n",
        "print(train_feature_resize.shape)\n",
        "\n",
        "test_pub_feature_resize = []\n",
        "test_pub_feature = np.reshape(np.array(test_pub_featuresets, dtype = 'float32'), (-1, 48, 48, 1))\n",
        "test_pub_emotion = np.reshape(np.array(test_pub_emotionsets, dtype = 'float32'), (-1))\n",
        "for i in range(test_pub_feature.shape[0]):\n",
        "    if i%1000 == 0:\n",
        "        print('now resize 48 --> 224 pub test set')\n",
        "    test_pub_feature_resize.append(resize(test_pub_feature[i], 224))\n",
        "test_pub_feature_resize = np.reshape(np.array(test_pub_feature_resize, dtype = 'float32'), (-1, 224, 224,1))\n",
        "print(test_pub_feature_resize.shape)\n",
        "\n",
        "test_pri_feature_resize = []\n",
        "test_pri_feature = np.reshape(np.array(test_pri_featuresets, dtype = 'float32'), (-1, 48, 48, 1))\n",
        "test_pri_emotion = np.reshape(np.array(test_pri_emotionsets, dtype = 'float32'), (-1))\n",
        "for i in range(test_pri_feature.shape[0]):\n",
        "    if i%1000 == 0:\n",
        "        print('now resize 48 --> 224 pri test set')\n",
        "    test_pri_feature_resize.append(resize(test_pri_feature[i], 224))\n",
        "test_pri_feature_resize = np.reshape(np.array(test_pri_feature_resize, dtype = 'float32'), (-1, 224, 224,1))\n",
        "print(test_pri_feature_resize.shape)\n",
        "\n",
        "#print(train_feature[0:2])\n",
        "\n",
        "batch_size = 32\n",
        "num_batches = 100\n",
        "\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "X = tf.placeholder(tf.float32, [32, 224, 224, 1])\n",
        "Y = tf.placeholder(tf.int32)\n",
        "    \n",
        "# 用来创建卷积层并把本层的参数存入参数列表\n",
        "# input_op:输入的tensor name:该层的名称 kh:卷积层的高 kw:卷积层的宽 n_out:输出通道数，dh:步长的高 dw:步长的宽，p是参数列表\n",
        "def conv_op(input_op, name, kh, kw, n_out, dh, dw, p):\n",
        "    #获取input_op的通道数\n",
        "    n_in = input_op.get_shape()[-1].value\n",
        "    with tf.name_scope(name) as scope:\n",
        "        #卷积核参数\n",
        "        kernel = tf.get_variable(scope + \"w\", shape = [kh, kw, n_in, n_out], dtype = tf.float32, initializer = tf.contrib.layers.xavier_initializer_conv2d())\n",
        "        #对input_op进行卷积处理，卷及和为kernel，步长\n",
        "        #第一个参数需要做卷积的输入图像，是一个Tensor，[batch, in_height, in_width, in_channels]是一个4维的Tensor，float32和float64之一\n",
        "        #第二个参数相当于CNN中的卷积核，是一个Tensor，[filter_height, filter_width, in_channels, out_channels]类型与参数input相同，第三维in_channels，是input的第四维\n",
        "        #第三个参数卷积时在图像每一维的步长，这是一个一维的向量，长度4\n",
        "        #第四个参数padding：string类型的量，只能是\"SAME\",\"VALID\"其中之一，SAME可以停留在图像边缘\n",
        "        #结果返回一个Tensor，这个输出，就是我们常说的feature map，shape仍然是[batch, height, width, channels]\n",
        "        conv = tf.nn.conv2d(input_op, kernel, (1, dh, dw, 1), padding = \"SAME\")\n",
        "        #创建一个张量，用0.0来填充\n",
        "        bias_init_val = tf.constant(0.0, shape = [n_out], dtype = tf.float32)\n",
        "        #转成可训练的参数，可以对他用Optimizer\n",
        "        biases = tf.Variable(bias_init_val, trainable = True, name = 'b')\n",
        "        #将偏差项bias加到conv上面，这里是bias必须是一维的\n",
        "        z = tf.nn.bias_add(conv, biases)\n",
        "        #卷积层的输出\n",
        "        activation = tf.nn.relu(z, name = scope)\n",
        "        #将kernel和biases加到参数列表\n",
        "        p += [kernel, biases]\n",
        "        return activation\n",
        "\n",
        "#定义全连接层\n",
        "def fc_op(input_op, name, n_out, p):\n",
        "    #获取通道数\n",
        "    n_in = input_op.get_shape()[-1].value\n",
        "    \n",
        "    with tf.name_scope(name) as scope:\n",
        "        #创建全连接层的参数，只有两个维度，也用xavier_initializer来初始化\n",
        "        kernel = tf.get_variable(scope+\"w\", shape = [n_in, n_out], dtype = tf.float32, initializer = tf.contrib.layers.xavier_initializer())\n",
        "        #初始化biases，这里用0.1来填充了\n",
        "        biases = tf.Variable(tf.constant(0.1, shape = [n_out], dtype = tf.float32), name = 'b')\n",
        "        activation = tf.nn.relu_layer(input_op, kernel, biases, name = scope)\n",
        "        p += [kernel, biases]\n",
        "        return activation\n",
        "\n",
        "#定义最大池化层的创建函数\n",
        "#maxpool即领域内取最大\n",
        "def mpool_op(input_op, name, kh, kw, dh, dw):\n",
        "    #这里tf.nn.max_pool(value, ksize, strides, padding, name=None)\n",
        "    #value输入通常是feature map\n",
        "    #池化窗口的大小，不再batch和channel上池化，所以两个为1\n",
        "    #窗口在每个维度上的滑动步长\n",
        "    #和卷积类似\n",
        "    #返回一个Tensor，类型不变，shape仍然是[batch, height, width, channels]这种形式\n",
        "    return tf.nn.max_pool(input_op, ksize = [1, kh, kw, 1], strides = [1, dh, dw, 1], padding = 'SAME', name = name)\n",
        "\n",
        "\n",
        "#创建VGGNET-16的网络结构\n",
        "def inference_op(input_op, keep_prob):\n",
        "    p = []\n",
        "    conv1_1 = conv_op(input_op, name = \"conv1_1\", kh = 3, kw = 3, n_out = 64, dh = 1, dw = 1, p = p)\n",
        "    conv1_2 = conv_op(conv1_1, name = \"conv1_2\", kh = 3, kw = 3, n_out = 64, dh = 1, dw = 1, p = p)\n",
        "    #这里每次都会输出结果的边长减半，但是通道数加倍了\n",
        "    pool1 = mpool_op(conv1_2, name = \"pool1\", kh = 2, kw = 2, dw = 2, dh = 2)\n",
        "    \n",
        "    conv2_1 = conv_op(pool1, name = \"conv2_1\", kh = 3, kw = 3, n_out = 128, dh = 1, dw = 1, p = p)\n",
        "    conv2_2 = conv_op(conv2_1, name = \"conv2_2\", kh = 3, kw = 3, n_out = 128, dh = 1, dw = 1, p = p)\n",
        "    pool2 = mpool_op(conv2_2, name = \"pool1\", kh = 2, kw = 2, dw = 2, dh = 2)\n",
        "    \n",
        "    conv3_1 = conv_op(pool2, name = \"conv3_1\", kh = 3, kw = 3, n_out = 256, dh = 1, dw = 1, p = p)\n",
        "    conv3_2 = conv_op(conv3_1, name = \"conv3_2\", kh = 3, kw = 3, n_out = 256, dh = 1, dw = 1, p = p)\n",
        "    conv3_3 = conv_op(conv3_2, name = \"conv3_3\", kh = 3, kw = 3, n_out = 256, dh = 1, dw = 1, p = p)\n",
        "    pool3 = mpool_op(conv3_3, name = \"pool3\", kh = 2, kw = 2, dh = 2, dw = 2)\n",
        "    \n",
        "    conv4_1 = conv_op(pool3, name = \"conv4_1\", kh = 3, kw = 3, n_out = 512, dh = 1, dw = 1, p = p)\n",
        "    conv4_2 = conv_op(conv4_1, name = \"conv4_2\", kh = 3, kw = 3, n_out = 512, dh = 1, dw = 1, p = p)\n",
        "    conv4_3 = conv_op(conv4_2, name = \"conv4_3\", kh = 3, kw = 3, n_out = 512, dh = 1, dw = 1, p = p)\n",
        "    pool4 = mpool_op(conv4_3, name = \"pool4\", kh = 2, kw = 2, dh = 2, dw = 2)\n",
        "    \n",
        "    conv5_1 = conv_op(pool4, name = \"conv5_1\", kh = 3, kw = 3, n_out = 512, dh = 1, dw = 1, p = p)\n",
        "    conv5_2 = conv_op(conv5_1, name = \"conv5_2\", kh = 3, kw = 3, n_out = 512, dh = 1, dw = 1, p = p)\n",
        "    conv5_3 = conv_op(conv5_2, name = \"conv5_3\", kh = 3, kw = 3, n_out = 512, dh = 1, dw = 1, p = p)\n",
        "    pool5 = mpool_op(conv5_3, name = \"pool5\", kh = 2, kw = 2, dh = 2, dw = 2)\n",
        "    \n",
        "    shp = pool5.get_shape()\n",
        "    #将每个样本化为长度为（长*宽*通道）的一维向量\n",
        "    flattened_shape = shp[1].value * shp[2].value * shp[3].value\n",
        "    resh1 = tf.reshape(pool5, [-1, flattened_shape], name = \"resh1\")\n",
        "    \n",
        "    #链接到一个隐含节点为4096的全连接层\n",
        "    fc6 = fc_op(resh1, name = \"fc6\", n_out = 4096, p = p)\n",
        "    #dropout防止或减轻过拟合而使用的函数，它一般用在全连接层。\n",
        "    #Dropout就是在不同的训练过程中随机扔掉一部分神经元。\n",
        "    #训练时的保留率为0.5，预测时为1.0\n",
        "    fc6_drop = tf.nn.dropout(fc6, keep_prob, name = \"fc6_drop\")\n",
        "    #fc6_drop = fc6\n",
        "    fc7 = fc_op(fc6_drop, name = \"fc7\", n_out = 4096, p = p)\n",
        "    fc7_drop = tf.nn.dropout(fc7, keep_prob, name = \"fc7_drop\")\n",
        "    #fc7_drop = fc7\n",
        "    fc8 = fc_op(fc7_drop, name = \"fc8\", n_out = 7, p = p)\n",
        "    #得到分类输出概率\n",
        "    softmax = tf.nn.softmax(fc8)\n",
        "    #得到概率最大的类别\n",
        "    predictions = tf.argmax(softmax, 1)\n",
        "    #print('in inference op : softmax', softmax)\n",
        "    #print('in inference op : prediction',predictions)\n",
        "    return predictions, softmax\n",
        "\n",
        "\n",
        "#这里通道变多可以增加表达能力，每个通道都是由一个卷积核算出来的，有的特征对不同的卷积核敏感，多通道可以把他们都保留下来\n",
        "def train_vgg():\n",
        "    predictions, softmax = inference_op(X, keep_prob)\n",
        "    \n",
        "    #print('in train vgg softmax', softmax)\n",
        "    \n",
        "    \n",
        "    #\n",
        "    #这里肯定有问题\n",
        "    #\n",
        "    cross_entropy = tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = Y, logits = softmax))\n",
        "    loss = tf.reduce_mean(cross_entropy)\n",
        "    \n",
        "    train_op = tf.train.GradientDescentOptimizer(0.001).minimize(loss)\n",
        "    \n",
        "    #初始化全局参数\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        print('going to strat train')\n",
        "        for i in range(100):\n",
        "            start = 0\n",
        "            end = start + batch_size\n",
        "            step = 0\n",
        "            while(end < len(train_feature_emotion)):\n",
        "                #这里可能有问题\n",
        "                #\n",
        "                #\n",
        "                #\n",
        "                loss_ = sess.run([predictions, loss], feed_dict = {X:train_feature_resize[start:end], keep_prob:0.5, Y:train_emotion[start:end]})\n",
        "                start += batch_size\n",
        "                end += batch_size\n",
        "                if step%100 == 0:\n",
        "                    #print(tf.argmax(softmax, 1).eval())\n",
        "                    print('save model   round: ', i,'step: ' , step, 'the loss: ', loss_)\n",
        "                step += 1\n",
        "                \n",
        "            if i%2 == 0:\n",
        "                print('goint to start public prediction')\n",
        "                print('the length of test_pub_emotion :' ,len(test_pub_emotion))\n",
        "                start1 = 0\n",
        "                end1 = start1 + batch_size\n",
        "                k = 0\n",
        "                while(end1 < len(test_pub_emotion)):\n",
        "                    predict = sess.run(predictions, feed_dict = {X:test_pub_feature_resize[start1:end1], keep_prob:1})\n",
        "                    #prediction.append(predict.tolist())\n",
        "                    accurate = test_pub_emotion[start1:end1]\n",
        "                    \n",
        "                    if  end1%512 == 0:\n",
        "                        print(predict)\n",
        "                        #print(accurate)\n",
        "                \n",
        "                    for w in range(len(predict)):\n",
        "                        if predict[w] == accurate[w]:\n",
        "                            #print(predict[w], accurate[w])\n",
        "                            k += 1                   \n",
        "                    start1 += batch_size\n",
        "                    end1 += batch_size            \n",
        "                accurate_rate = k / len(test_pub_emotion)\n",
        "                print('end public prediction')\n",
        "                print('the public accurate is : ', accurate_rate)\n",
        "                  \n",
        "train_vgg()\n",
        "#use_vgg()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hrhere\n",
            "now resize 48 --> 224 train set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-31e6009c7a2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'now resize 48 --> 224 train set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_feature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mtrain_feature_resize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_feature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0mtrain_feature_resize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_feature_resize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_feature_resize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-31e6009c7a2b>\u001b[0m in \u001b[0;36mresize\u001b[0;34m(src, new_size)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;31m#双线性插值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                 \u001b[0mvalue0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc_x_1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msrc_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msrc_y_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_x_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc_x\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msrc_x_0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msrc_y_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_x_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                 \u001b[0mvalue1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc_x_1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msrc_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msrc_y_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_x_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc_x\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msrc_x_0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msrc_y_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_x_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mdst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdst_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_y_1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msrc_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvalue0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc_y\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msrc_y_0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvalue1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Fj18u_K-o13m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "64591d09-d6e4-4608-b0be-a7923f7fb32a"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gpg: keybox '/tmp/tmpfuc08amm/pubring.gpg' created\n",
            "gpg: /tmp/tmpfuc08amm/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gcgltATMo2pQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 指定Google Drive云端硬盘的根目录，名为drive\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}